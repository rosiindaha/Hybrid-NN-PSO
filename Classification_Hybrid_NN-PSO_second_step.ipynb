{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run fungsi_save.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pilih data fitur masukan NN1\n",
    "train_data = pd.read_csv('data_training.csv', sep=',',header=None)\n",
    "train_data = train_data.values\n",
    "post = pd.read_csv('data_feature1_pos.csv', sep=',',header=None)\n",
    "post = np.int_(post)\n",
    "total_features = np.size(train_data, axis=1)-2\n",
    "print(total_features)\n",
    "output_train_data = train_data[:,total_features+1] #output aja lym\n",
    "output_train_data = np.int_(output_train_data)\n",
    "train_data = train_data[:,:total_features]\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [] #index fitur yang gak kepake\n",
    "for i in range(len(post)):\n",
    "    if post[i,0] == 0:\n",
    "        a.append(i)\n",
    "train_data = np.delete(train_data, a ,axis=1) #data fitur yang udah terseleksi\n",
    "print(\"Number of training samples is\", len(train_data))\n",
    "print(np.size(train_data,axis=1))\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data validasi\n",
    "validasi_data = pd.read_csv('data_testing.csv', sep=',',header=None)\n",
    "validasi_data = validasi_data.values\n",
    "b = [] #index fitur yang gak kepake\n",
    "for i in range(len(validasi_data)):\n",
    "    if validasi_data[i,29] == 2:\n",
    "        b.append(i)\n",
    "validasi_data = np.delete(validasi_data, b ,axis=0) #data fitur limfo aja\n",
    "output_validasi_data = validasi_data[:,total_features] #output aja untuk output 2\n",
    "output_validasi_data = np.int_(output_validasi_data)\n",
    "validasi_data = validasi_data[:,0:total_features] #fitur aja tanpa output dan fiturnya lengkap\n",
    "validasi_data = np.delete(validasi_data, a ,axis=1) #data fitur yang udah terseleksi\n",
    "\n",
    "#save_data1(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = np.size(train_data,1)\n",
    "n_hidden = 20\n",
    "n_classes = 2\n",
    "n_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(params):\n",
    "\n",
    "    # Neural network architecture\n",
    "    global n_inputs\n",
    "    global n_hidden\n",
    "    global n_classes\n",
    "\n",
    "    w1_total = n_inputs*n_hidden\n",
    "    b1_total = w1_total+n_hidden\n",
    "    w2_total = b1_total+(n_hidden*n_classes)\n",
    "    b2_total = w2_total+n_classes\n",
    "    \n",
    "    # Roll-back the weights and biases\n",
    "    W1 = params[0:w1_total].reshape((n_inputs,n_hidden))\n",
    "    b1 = params[w1_total:b1_total].reshape((n_hidden,))\n",
    "    W2 = params[b1_total:w2_total].reshape((n_hidden,n_classes))\n",
    "    b2 = params[w2_total:b2_total].reshape((n_classes,))\n",
    "\n",
    "    # Perform forward propagation\n",
    "    z1 = train_data.dot(W1) + b1  # Pre-activation in Layer 1\n",
    "    a1 = np.tanh(z1)     # Activation in Layer 1 #belum pasti pake fungsi aktivasi apa\n",
    "    z2 = a1.dot(W2) + b2 # Pre-activation in Layer 2\n",
    "    logits = z2          # Logits for Layer 2\n",
    "\n",
    "    # Compute for the softmax of the logits\n",
    "    exp_scores = np.exp(logits)\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "    # Compute for the negative log likelihood #belum pasti loss functionnya pake apa\n",
    "    N = len(train_data) # Number of samples\n",
    "    corect_logprobs = -np.log(probs[range(N), output_train_data])\n",
    "    loss = np.sum(corect_logprobs) / N\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    n_particles = x.shape[0]\n",
    "    j = [forward_prop(x[i]) for i in range(n_particles)]\n",
    "    return np.array(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize swarm\n",
    "options = {'c1': 0.5, 'c2': 0.3, 'w':0.9}\n",
    "\n",
    "# Call instance of PSO\n",
    "dimensions = (n_inputs * n_hidden) + (n_hidden * n_classes) + n_hidden + n_classes\n",
    "optimizer = ps.single.GlobalBestPSO(n_particles=20, dimensions=dimensions, options=options)\n",
    "\n",
    "# Perform optimization\n",
    "cost, pos = optimizer.optimize(f, iters=300) #fungsi verbose dan print step error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyswarms.utils.plotters import plot_cost_history\n",
    "plot_cost_history(cost_history=optimizer.cost_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kurang test file\n",
    "def predict(a, pos): #a = data training atau data test\n",
    "\n",
    "    # Neural network architecture\n",
    "    global n_inputs\n",
    "    global n_hidden\n",
    "    global n_classes\n",
    "\n",
    "    w1_total = n_inputs*n_hidden\n",
    "    b1_total = w1_total+n_hidden\n",
    "    w2_total = b1_total+(n_hidden*n_classes)\n",
    "    b2_total = w2_total+n_classes\n",
    "    \n",
    "    # Roll-back the weights and biases\n",
    "    W1 = pos[0:w1_total].reshape((n_inputs,n_hidden))\n",
    "    b1 = pos[w1_total:b1_total].reshape((n_hidden,))\n",
    "    W2 = pos[b1_total:w2_total].reshape((n_hidden,n_classes))\n",
    "    b2 = pos[w2_total:b2_total].reshape((n_classes,))\n",
    "    save_params2(W1,b1,W2,b2)\n",
    "    # Perform forward propagation\n",
    "    z1 = a.dot(W1) + b1  # Pre-activation in Layer 1\n",
    "    a1 = np.tanh(z1)     # fungsi aktivasi belum fix\n",
    "    z2 = a1.dot(W2) + b2 # Pre-activation in Layer 2\n",
    "    logits = z2          # Logits for Layer 2\n",
    "\n",
    "    y_pred = np.argmax(logits, axis=1)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### data testing\n",
    "data_test =  pd.read_csv('data_testing_NN1.csv', sep=',',header=None)\n",
    "data_test = data_test.values\n",
    "len_data_test = np.size(data_test, axis=1)-1\n",
    "output_test_data = data_test[:,len_data_test] #output aja limfo\n",
    "output_test_data = np.int_(output_test_data)\n",
    "data_test = data_test[:,:len_data_test]\n",
    "data_test = np.delete(data_test, a ,axis=1) #data fitur yang udah terseleksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_train = confusion_matrix(output_train_data, predict(train_data, pos))\n",
    "cm_validasi = confusion_matrix(output_validasi_data, predict(validasi_data, pos))\n",
    "cm_test = confusion_matrix(output_test_data, predict(data_test, pos))\n",
    "cm_validasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.array(['non-lymphoblast',\"lymphoblast\",\"non-lymphoid\"])\n",
    "np.set_printoptions(precision=2)\n",
    "cm_t = plot_confusion_matrix(output_train_data, predict(train_data, pos), classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "cm_v = plot_confusion_matrix(output_validasi_data, predict(validasi_data, pos), classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "cm_te = plot_confusion_matrix(output_test_data, predict(data_test, pos), classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_t.figure.savefig('fix2(balanced)/step2/NN/train1.png')\n",
    "cm_v.figure.savefig('fix2(balanced)/step2/NN/validasi1.png')\n",
    "cm_te.figure.savefig('fix2(balanced)/step2/NN/test1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Presisi data training limfoblas : \", precision(1,cm_train))\n",
    "print(\"Recall data training limfoblas (sensitivitas) : \", recall(1,cm_train))\n",
    "print(\"Presisi rerata data training : \", precision_macro_average(cm_train))\n",
    "print(\"Presisi rerata data training : \", recall_macro_average(cm_train))\n",
    "print(\"Akurasi data training : \", accuracy(cm_train))\n",
    "print(\"F1 Score data training : \", f1_score(precision_macro_average(cm_train),recall_macro_average(cm_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Presisi data validasi limfoblas : \", precision(1,cm_validasi))\n",
    "print(\"Recall data validasi limfoblas : \", recall(1,cm_validasi))\n",
    "print(\"Presisi rerata data validasi : \", precision_macro_average(cm_validasi))\n",
    "print(\"Presisi rerata data validasi : \", recall_macro_average(cm_validasi))\n",
    "print(\"Akurasi data validasi : \", accuracy(cm_validasi))\n",
    "print(\"F1 Score data validasi : \", f1_score(precision_macro_average(cm_validasi),recall_macro_average(cm_validasi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Presisi data test limfoblas : \", precision(1,cm_test))\n",
    "print(\"Recall data test limfoblas : \", recall(1,cm_test))\n",
    "print(\"Presisi rerata data test : \", precision_macro_average(cm_test))\n",
    "print(\"Presisi rerata data test : \", recall_macro_average(cm_test))\n",
    "print(\"Akurasi data test : \", accuracy(cm_test))\n",
    "print(\"F1 Score data test : \", f1_score(precision_macro_average(cm_test),recall_macro_average(cm_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos2 = [i for i in pos]\n",
    "pos2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_pos_step1('step2/neuron_step2.csv',(n_hidden,optimizer.cost_history,accuracy(cm_train),accuracy(cm_validasi)))\n",
    "save_pos_step1('fix2(balanced)/step2/NN/perfo_step2.csv',(accuracy(cm_train),accuracy(cm_validasi),accuracy(cm_test),pos2,optimizer.cost_history))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
